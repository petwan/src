---
title: âš¡ç†è§£ LangChain 1.0 çš„å·¥ä½œæµ
date: 2026-01-05
tags: [LLMs]
description: ä¸€ç¯‡ LangChain v1.0 çš„å…¥é—¨ä»‹ç»ï¼ŒåŸºäº Google çš„ Pergel æ¨¡å¼ï¼Œä»¥ä¸€ä¸ªä¾‹å­è¯´æ˜æ•´ä½“çš„æ‰§è¡Œè¿‡ç¨‹ï¼Œç²—ç•¥ä»‹ç»ä¸­é—´ä»¶çš„ä¸€äº›åŸºæœ¬æ¦‚å¿µã€‚
draft: false
---

# âš¡ç†è§£ LangChain 1.0 çš„å·¥ä½œæµ

> è¿™æ˜¯ä¸€ç¯‡å…¥é—¨çš„æ–‡ç« ï¼Œä»…ç”¨äºå­¦ä¹ ï¼Œä¼ä¸šçº§æ–¹æ¡ˆä¸åœ¨è¿™ä¸ªæ–‡ç« é‡Œä»‹ç»ã€‚

AI åº”ç”¨çš„å¼€å‘æ­£å˜å¾—è¶Šæ¥è¶Šå¤æ‚ï¼Œå•çº¯è°ƒç”¨ä¸€æ¬¡ API å¾€å¾€è§£å†³ä¸äº†é—®é¢˜ã€‚æˆ‘ä»¬éœ€è¦è®© AI åƒä¾¦æ¢ä¸€æ ·æ€è€ƒï¼Œåƒå›¢é˜Ÿä¸€æ ·åä½œï¼Œæ‰§è¡Œå¤šæ­¥éª¤ã€æœ‰çŠ¶æ€çš„å·¥ä½œæµã€‚

è¿™ä¸ªæ–‡ç« é€šè¿‡ä¸€ä¸ª **â€œç ´æ¡ˆå°ç»„â€** çš„æ¯”å–»ï¼Œæ¥è½»æ¾ç†è§£ LangChain ä¸­å¼ºå¤§çš„å·¥ä½œæµå¼•æ“â€”â€”**LangGraph** çš„æ ¸å¿ƒæ€æƒ³ã€‚

> ğŸ’¡ æœ¬æ–‡åŸºäº LangChain 1.0ï¼Œ`pip install -U langchain` ã€‚

## 1. æ ¸å¿ƒæ¯”å–»ï¼šä¸€ä¸ªé«˜æ•ˆçš„ç ´æ¡ˆå°ç»„

æƒ³è±¡ä¸€ä¸ªé‡å¤§æ¡ˆä»¶ï¼Œè­¦å±€æˆç«‹äº†ä¸€ä¸ªä¸“é¡¹å°ç»„ï¼š

*   **ğŸ‘®â€â™‚ï¸ ä¾¦æŸ¥å‘˜ A**ï¼šè´Ÿè´£æ¢³ç†å«Œç–‘äººçš„æ—¶é—´çº¿ã€‚
*   **ğŸ‘©â€ğŸ’» æƒ…æŠ¥å‘˜ B**ï¼šè´Ÿè´£è°ƒå–å’Œåˆ†æç›‘æ§ã€é€šè®¯è®°å½•ã€‚
*   **ğŸ‘¨â€âš•ï¸ å¿ƒç†ä¸“å®¶ C**ï¼šè´Ÿè´£åˆ†æå«Œç–‘äººçš„è¡Œä¸ºä¸å¿ƒç†çŠ¶æ€ã€‚
*   **ğŸ‘¨â€âš–ï¸ æ³•å¾‹é¡¾é—® D**ï¼šè´Ÿè´£è¯„ä¼°è¯æ®æ˜¯å¦æ„æˆå®Œæ•´çš„æ³•å¾‹è¯æ®é“¾ã€‚

ä»–ä»¬çš„å·¥ä½œéƒ½å›´ç»•**åŒä¸€ä¸ªå«Œç–‘äºº**å±•å¼€ã€‚ä¸ºäº†é«˜æ•ˆåä½œï¼Œä»–ä»¬å…±äº«ä¸€ä»½**å”¯ä¸€çš„æ¡ˆä»¶æ¡£æ¡ˆ**ï¼Œé‡Œé¢è®°å½•äº†ï¼š
1.  ç›®å‰å·²æŒæ¡çš„æ‰€æœ‰è¯æ®
2.  å«Œç–‘äººçš„ä¾›è¿°
3.  ç›‘æ§/é€šè¯è®°å½•çš„å…³é”®ä¿¡æ¯
4.  å“ªäº›çº¿ç´¢å·²å¾—åˆ°éªŒè¯
5.  å“ªäº›ç–‘ç‚¹ä»éœ€è¿½æŸ¥

**ä½ ä½œä¸ºç»„é•¿**ï¼Œè´Ÿè´£åè°ƒè¿™4åæˆå‘˜ã€‚å·¥ä½œæŒ‰**è½®æ¬¡**è¿›è¡Œï¼Œæ¯è½®ä¸­ï¼Œæ¯ä½æˆå‘˜åªå¤„ç†è‡ªå·±ä¸“ä¸šé¢†åŸŸçš„ä»»åŠ¡ï¼Œå¹¶é€šè¿‡æ›´æ–°**æ¡ˆä»¶æ¡£æ¡ˆ**æ¥äº¤æ¢ä¿¡æ¯ï¼Œæœ€ç»ˆå…±åŒç ´æ¡ˆã€‚

### 1.1 ç¬¬ä¸€è½®ä¾¦æŸ¥
ç»„é•¿ä¸‹è¾¾åˆå§‹æŒ‡ä»¤ï¼Œå°ç»„æˆå‘˜å¼€å§‹å·¥ä½œå¹¶è®°å½•å‘ç°ï¼š
*   **ä¾¦æŸ¥å‘˜ A**ï¼šæ¢³ç†æ—¶é—´çº¿ â†’ å‘ç°ä¸€å¤„çŸ›ç›¾ç‚¹ â†’ **å†™å…¥æ¡£æ¡ˆ**ã€‚
*   **æƒ…æŠ¥å‘˜ B**ï¼šè°ƒå–æ¡ˆå‘åœ°ç›‘æ§ â†’ å‘ç°å…³é”®èº«å½± â†’ **å†™å…¥æ¡£æ¡ˆ**ã€‚
*   **å¿ƒç†ä¸“å®¶ C**ï¼šè§‚å¯Ÿåˆæ­¥è¡Œä¸º â†’ è®°å½•â€œæœ‰éšç’å¯èƒ½æ€§â€ â†’ **å†™å…¥æ¡£æ¡ˆ**ã€‚
*   **æ³•å¾‹é¡¾é—® D**ï¼šææ–™ä¸è¶³ï¼Œæš‚ä¸è¡ŒåŠ¨ã€‚

**ç¬¬ä¸€è½®ç»“æŸ**ï¼šç»„é•¿æ±‡æ€»æ‰€æœ‰äººçš„è®°å½•ï¼Œ**ç»Ÿä¸€æ›´æ–°æ¡ˆä»¶æ¡£æ¡ˆ**ã€‚

### 1.2 ç¬¬äºŒè½®åˆ†æ
ç»„é•¿åŸºäºæ›´æ–°åçš„æ¡£æ¡ˆï¼Œå†æ¬¡åˆ†æ´¾é’ˆå¯¹æ€§çš„ä»»åŠ¡ï¼š
*   **ä¾¦æŸ¥å‘˜ A**ï¼šç»“åˆBæä¾›çš„ç›‘æ§æ—¶é—´ï¼Œ**ä¿®æ­£**æ—¶é—´çº¿ã€‚
*   **æƒ…æŠ¥å‘˜ B**ï¼šæ ¹æ®Aä¿®æ­£çš„æ—¶é—´ï¼Œè°ƒå–å¯¹åº”æ—¶æ®µçš„æ‰‹æœºé€šè¯è®°å½•ã€‚
*   **å¿ƒç†ä¸“å®¶ C**ï¼šå‘ç°ä¾›è¿°ä¸ç›‘æ§æ—¶é—´çŸ›ç›¾ï¼Œæ ‡è®°â€œå»ºè®®è¿›è¡Œå‹åŠ›æµ‹è¯•â€ã€‚
*   **æ³•å¾‹é¡¾é—® D**ï¼šå¼€å§‹å®¡è§†å½“å‰è¯æ®çš„å…³è”æ€§ã€‚

**ç¬¬äºŒè½®ç»“æŸ**ï¼šæ¡£æ¡ˆå†æ¬¡è¢«**ç»Ÿä¸€æ›´æ–°**ï¼Œçº¿ç´¢æ›´æ¸…æ™°ï¼ŒçŸ›ç›¾æ›´çªå‡ºã€‚

### 1.3 ç¬¬ä¸‰è½®å®šæ¡ˆ
ç»„é•¿å‘ç°ï¼Œè¯æ®é“¾å·²å®Œæ•´é—­åˆï¼Œæ‰€æœ‰ä¾›è¿°ä¸€è‡´ï¼Œæ²¡æœ‰æˆå‘˜æå‡ºæ–°çš„ç–‘ç‚¹æˆ–éœ€è¦è¡¥å……çš„ä¿¡æ¯ã€‚
**æ¡ˆä»¶å®£å‘Šä¾¦ç ´ï¼Œå·¥ä½œæµç»“æŸã€‚**

## 2. ä»â€œç ´æ¡ˆâ€åˆ°â€œLangGraphâ€ï¼šæ ¸å¿ƒæ¦‚å¿µæ˜ å°„

è¿™ä¸ªç”ŸåŠ¨çš„ä¾‹å­ï¼Œå®Œç¾æ˜ å°„äº† LangGraph çš„å››å¤§æ ¸å¿ƒæŠ½è±¡ï¼š

| ç ´æ¡ˆå°ç»„                 | LangGraph æ¦‚å¿µ                         | ä½œç”¨                                                |
| :----------------------- | :------------------------------------- | :-------------------------------------------------- |
| **æ¡ˆä»¶æ¡£æ¡ˆ**             | **State (çŠ¶æ€)**                       | å·¥ä½œæµä¸­å…±äº«ã€éšæ—¶é—´å˜åŒ–çš„æ ¸å¿ƒæ•°æ®ã€‚                |
| **å°ç»„æˆå‘˜(A, B, C, D)** | **Node (èŠ‚ç‚¹)**                        | æ‰§è¡Œå…·ä½“ä»»åŠ¡çš„å•å…ƒï¼ˆå¯ä»¥æ˜¯å‡½æ•°ã€LLMè°ƒç”¨ã€å·¥å…·ç­‰ï¼‰ã€‚ |
| **ç»„é•¿ (ä½ )**            | **Graph (å›¾) / Orchestrator (ç¼–æ’å™¨)** | å®šä¹‰èŠ‚ç‚¹æ‰§è¡Œé¡ºåºå’Œé€»è¾‘çš„è“å›¾ã€‚                      |
| **â€œè½®æ¬¡â€å·¥ä½œæ¨¡å¼**       | **Stateful Workflow (æœ‰çŠ¶æ€å·¥ä½œæµ)**   | çŠ¶æ€åœ¨ä¸€è½®è½®æ‰§è¡Œä¸­ä¼ é€’å’Œæ¼”åŒ–ï¼Œç›´è‡³è¾¾åˆ°ç»ˆç‚¹ã€‚        |

### 2.1 ä¸¤ä¸ªå…³é”®çš„æŠ€æœ¯æŒ‘æˆ˜ä¸ LangGraph çš„è§£å†³æ–¹æ¡ˆ

æˆ‘ä»¬çš„â€œç ´æ¡ˆâ€æµç¨‹è™½ç„¶æ¸…æ™°ï¼Œä½†ä¹Ÿå¼•å‡ºäº†ä¸¤ä¸ªæ½œåœ¨é—®é¢˜ï¼š

1.  **æ¡£æ¡ˆæ›´æ–°å†²çª**ï¼šå¦‚æœAå’ŒBåŒæ—¶ä¿®æ”¹äº†æ¡£æ¡ˆçš„åŒä¸€éƒ¨åˆ†æ€ä¹ˆåŠï¼Ÿ
2.  **æµç¨‹ä¸­æ–­ä¸å›æº¯**ï¼šå¦‚æœä¸­é€”éœ€è¦æš‚åœå®¡è®®ï¼Œæˆ–è€…æƒ³æŸ¥çœ‹ä¹‹å‰çš„æ¨ç†æ­¥éª¤æ€ä¹ˆåŠï¼Ÿ

**LangGraph æä¾›äº†ä¼˜é›…çš„è§£å†³æ–¹æ¡ˆ**ï¼š
*   **çŠ¶æ€æ›´æ–°ç­–ç•¥ (State Reducers)**ï¼šç²¾ç¡®å®šä¹‰æ¯ä¸ªä¿¡æ¯å­—æ®µçš„åˆå¹¶é€»è¾‘ï¼ˆå¦‚è¦†ç›–ã€è¿½åŠ ç­‰ï¼‰ï¼Œè§£å†³å†²çªã€‚
*   **æ£€æŸ¥ç‚¹ (Checkpoints)**ï¼šè‡ªåŠ¨ä¿å­˜æ¯ä¸€è½®ç»“æŸåçš„å®Œæ•´çŠ¶æ€ï¼Œå®ç°æš‚åœã€æ¢å¤å’Œæ­¥éª¤è¿½æº¯ã€‚

## 3. LangGraph å®æˆ˜ï¼šå¦‚ä½•æ„å»ºä½ çš„â€œç ´æ¡ˆå¼•æ“â€

ç†è§£äº†æ¯”å–»ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹ä»£ç ã€‚æ„å»ºä¸€ä¸ª LangGraph å·¥ä½œæµï¼Œå°±åƒç»„å»ºé‚£ä¸ªç ´æ¡ˆå°ç»„ã€‚

### 3.1 å®šä¹‰â€œæ¡ˆä»¶æ¡£æ¡ˆâ€ (State Schema) å’Œ èƒŒæ™¯ï¼ˆContext Schemaï¼‰
é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ç”¨ä»£ç å®šä¹‰æˆ‘ä»¬çš„â€œæ¡ˆä»¶æ¡£æ¡ˆâ€é‡Œå…·ä½“è®°å½•ä»€ä¹ˆã€‚è¿™é‡Œæˆ‘ä»¬ç”¨ `TypedDict` æ¥å£°æ˜ã€‚

```python
from typing import TypedDict, List, Annotated

# å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰çš„â€œåˆå¹¶ç­–ç•¥â€ï¼šå°†æ–°æ—¥å¿—è¿½åŠ åˆ°æ—§æ—¥å¿—åé¢
def append_log(old_log: List[str], new_log: List[str]) -> List[str]:
    return old_log + new_log

class CaseFileState(TypedDict):
    """
    æˆ‘ä»¬çš„æ¡ˆä»¶æ¡£æ¡ˆ Stateã€‚
    - `clues`: é»˜è®¤ä¸ºâ€œè¦†ç›–â€ç­–ç•¥ï¼Œæ–°çº¿ç´¢åˆ—è¡¨ç›´æ¥æ›¿æ¢æ—§çš„ã€‚
    - `investigation_log`: ä½¿ç”¨â€œè¿½åŠ â€ç­–ç•¥ï¼Œæ‰€æœ‰åˆ†æè®°å½•éƒ½ä¼šä¿ç•™ã€‚
    """
    clues: List[str]  # çº¿ç´¢åˆ—è¡¨ï¼Œé»˜è®¤æ›´æ–°ç­–ç•¥ä¸ºâ€œè¦†ç›–â€
    investigation_log: Annotated[List[str], append_log] # è°ƒæŸ¥æ—¥å¿—ï¼Œä½¿ç”¨â€œè¿½åŠ â€ç­–ç•¥

# ======= Context Schema: ä¸å˜çš„"æ¡ˆä»¶èƒŒæ™¯" =========
class CaseContext(TypedDict):
    """
    æ¡ˆä»¶èƒŒæ™¯ Context - å›ºå®šä¸å˜çš„ä¿¡æ¯
    - `case_id`: æ¡ˆä»¶ç¼–å·ï¼Œç”¨äºæ ‡è¯†
    - `jurisdiction`: æ³•å¾‹ç®¡è¾–åŒºåŸŸï¼Œå†³å®šé€‚ç”¨çš„æ³•å¾‹
    - `priority_level`: ä¼˜å…ˆçº§ï¼Œå¯èƒ½å½±å“èµ„æºåˆ†é…ï¼ˆä½†ä¸æ”¹å˜ï¼‰
    """
    case_id: str
    jurisdiction: str
    priority_level: str
```

**å…³é”®ç‚¹**ï¼š`Annotated` å’Œ `append_log` å‡½æ•°è®©æˆ‘ä»¬èƒ½ç²¾ç»†æ§åˆ¶ `investigation_log` å­—æ®µçš„æ›´æ–°æ–¹å¼ï¼Œè¿™æ­£æ˜¯ LangGraph çµæ´»æ€§çš„ä½“ç°ã€‚

::: info Stateæ›´æ–°ç­–ç•¥
ä¸Šé¢çš„ä¾‹å­ä¸­ï¼ŒStateæ›´æ–°ç­–ç•¥æ˜¯è¦†ç›–ï¼Œå³æ¯æ¬¡è¿è¡ŒèŠ‚ç‚¹æ—¶ï¼Œéƒ½ä¼šå°†èŠ‚ç‚¹çš„è¾“å‡ºç»“æœè¦†ç›–åˆ° State ä¸­ã€‚
LangGraph å…è®¸ä¸ºæ¯ä¸ªçŠ¶æ€å­—æ®µæŒ‡å®š reducer å‡½æ•°ï¼Œæ§åˆ¶å¦‚ä½•åˆå¹¶æ–°å€¼å’Œæ—§å€¼ï¼Œé€šè¿‡ TypedDict + Annotated å®ç°ã€‚
- ç­–ç•¥ 1ï¼šè¦†ç›–ï¼ˆReplaceï¼‰ â€”â€” é»˜è®¤å°±æ˜¯å¦‚æ­¤ï¼ˆä½†å¯æ˜¾å¼å£°æ˜ï¼‰
- ç­–ç•¥ 2ï¼šç´¯åŠ ï¼ˆAccumulate / Appendï¼‰ â€”â€” é€‚ç”¨äºåˆ—è¡¨ç­‰
- ç­–ç•¥ 3ï¼šæœ€å¤§å€¼/æœ€å°å€¼/è‡ªå®šä¹‰é€»è¾‘
:::


> ğŸ’¡ å°ç»„æˆå‘˜ï¼ˆNodeï¼‰è¿è¡Œæ—¶ï¼Œå¯ä»¥æŸ¥çœ‹ Context å¯¹åº”çš„å†…å®¹ï¼Œä½†æ˜¯ä¸èƒ½ä¿®æ”¹ã€‚

é™¤äº† `State Schema` å’Œ `Context Schema`ï¼Œ LangGraph è¿˜éœ€è¦ä¸€ä¸ªé¢å¤–çš„æ¦‚å¿µï¼š**Input Schema** å’Œ **Output Schema**ã€‚

- `Input Schema` æ˜¯ä¸€å¼€å§‹å¿…é¡»å¸¦è¿›ç³»ç»Ÿçš„ä¿¡æ¯å†…å®¹å½¢å¼ï¼Œå¦‚æœæ²¡æœ‰ç»™å®šInput Schemaï¼ŒStateGraphé»˜è®¤æŠŠState Scheam ä½œä¸º Input Schemaã€‚

- `Output Schema` æ˜¯ Node è¿è¡Œè¿‡ç¨‹ä¸­äº§ç”Ÿçš„å†…å®¹å½¢å¼ï¼Œå¦‚æœæ²¡æœ‰ç»™å®šOutput Schemaï¼ŒStateGraphé»˜è®¤æŠŠState Scheam ä½œä¸º Output Schemaã€‚


### 3.2 æ‹›å‹Ÿâ€œå°ç»„æˆå‘˜â€ (å®šä¹‰ Nodes)
æ¯ä¸ªèŠ‚ç‚¹éƒ½æ˜¯ä¸€ä¸ªæ™®é€šçš„ Python å‡½æ•°ï¼Œå®ƒæ¥æ”¶å½“å‰çš„ `State`ï¼Œå¹¶è¿”å›è¦æ›´æ–°åˆ° `State` ä¸­çš„å†…å®¹ã€‚

```python
def detective_node(state: CaseFileState) -> dict:
    """ä¾¦æŸ¥å‘˜èŠ‚ç‚¹ï¼šå‘ç°æ–°çº¿ç´¢"""
    new_clue = "å«Œç–‘äººåœ¨æ¡ˆå‘æ—¶é—´å£°ç§°åœ¨å®¶ï¼Œä½†æ— è¯äººã€‚"
    return {
        "clues": [new_clue], # æ›´æ–°clueså­—æ®µ
        "investigation_log": [f"[ä¾¦æŸ¥å‘˜] å‘ç°äº†çº¿ç´¢ï¼š{new_clue}"]
    }

def analyst_node(state: CaseFileState) -> dict:
    """æƒ…æŠ¥å‘˜èŠ‚ç‚¹ï¼šåˆ†æçº¿ç´¢å¹¶è®°å½•"""
    current_clues = state["clues"]
    analysis = f"ç›®å‰å…±æœ‰ {len(current_clues)} æ¡çº¿ç´¢éœ€è¦äº¤å‰éªŒè¯ã€‚"
    return {
        "investigation_log": [f"[æƒ…æŠ¥å‘˜] åˆ†ææŠ¥å‘Šï¼š{analysis}"]
        # æ²¡æœ‰è¿”å› `clues`ï¼Œæ‰€ä»¥ `clues` å­—æ®µå°†ä¿æŒä¸å˜
    }
```

### 3.3 ä»»å‘½â€œç»„é•¿â€å¹¶åˆ¶å®šæµç¨‹ (æ„å»º Graph)
ç°åœ¨ï¼Œæˆ‘ä»¬åˆ›å»ºå›¾ï¼ˆç»„é•¿ï¼‰ï¼Œæ·»åŠ èŠ‚ç‚¹ï¼ˆæˆå‘˜ï¼‰ï¼Œå¹¶å®‰æ’ä»–ä»¬çš„å·¥ä½œé¡ºåºï¼ˆè¾¹ï¼‰ã€‚

```python
from langgraph.graph import StateGraph, START, END

# 1. åˆ›å»ºä¸€ä¸ªå›¾ï¼Œå¹¶å‘Šè¯‰å®ƒæˆ‘ä»¬æ¡£æ¡ˆçš„æ ¼å¼ (CaseFileState)
workflow_builder = StateGraph(state_schema=CaseFileState, context_schema=CaseContext)

# 2. å°†æˆ‘ä»¬çš„â€œå°ç»„æˆå‘˜â€ï¼ˆèŠ‚ç‚¹å‡½æ•°ï¼‰æ·»åŠ åˆ°å›¾ä¸­
workflow_builder.add_node("detective", detective_node)
workflow_builder.add_node("analyst", analyst_node)

# 3. åˆ¶å®šå·¥ä½œæµç¨‹
workflow_builder.add_edge(START, "detective")  # å¼€å§‹ -> å…ˆè®©ä¾¦æŸ¥å‘˜ä¸Š
workflow_builder.add_edge("detective", "analyst")  # ä¾¦æŸ¥å‘˜å®Œæˆå -> æƒ…æŠ¥å‘˜åˆ†æ
workflow_builder.add_edge("analyst", END)  # åˆ†æå®Œæˆå -> ç»“æŸ

# 4. ç¼–è¯‘æˆå¯æ‰§è¡Œçš„â€œå·¥ä½œæµå¼•æ“â€
investigation_workflow = workflow_builder.compile()

for key in workflow_builder.__dict__.keys():
    print(f"{key} >| {workflow_builder.__dict__[key]}")
```

### 3.4 å¯åŠ¨è°ƒæŸ¥ï¼
ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªåˆå§‹çš„â€œç©ºæ¡£æ¡ˆâ€æ¥å¯åŠ¨è¿™ä¸ªå·¥ä½œæµã€‚

```python
initial_state: CaseFileState = {"clues": [], "investigation_log": ["æ¡ˆä»¶å¯åŠ¨"]}

# æ‰§è¡Œå·¥ä½œæµï¼
final_state = investigation_workflow.invoke(initial_state)

print("æœ€ç»ˆçº¿ç´¢ï¼š", final_state["clues"])
print("\nå®Œæ•´è°ƒæŸ¥æ—¥å¿—ï¼š")
for log in final_state["investigation_log"]:
    print(" -", log)
```

**è¾“å‡ºå°†ä¼šæ˜¯ï¼š**
```
æœ€ç»ˆçº¿ç´¢ï¼š ['å«Œç–‘äººåœ¨æ¡ˆå‘æ—¶é—´å£°ç§°åœ¨å®¶ï¼Œä½†æ— è¯äººã€‚']

å®Œæ•´è°ƒæŸ¥æ—¥å¿—ï¼š
 - æ¡ˆä»¶å¯åŠ¨
 - [ä¾¦æŸ¥å‘˜] å‘ç°äº†çº¿ç´¢ï¼šå«Œç–‘äººåœ¨æ¡ˆå‘æ—¶é—´å£°ç§°åœ¨å®¶ï¼Œä½†æ— è¯äººã€‚
 - [æƒ…æŠ¥å‘˜] åˆ†ææŠ¥å‘Šï¼šç›®å‰å…±æœ‰ 1 æ¡çº¿ç´¢éœ€è¦äº¤å‰éªŒè¯ã€‚
```

çœ‹ï¼æ—¥å¿—è¢«å®Œç¾åœ°**ç´¯ç§¯**äº†ä¸‹æ¥ï¼Œè€Œçº¿ç´¢è¢«**æ›´æ–°**äº†ã€‚è¿™å°±æ˜¯æˆ‘ä»¬å®šä¹‰çš„ State Reducers åœ¨èµ·ä½œç”¨ã€‚

### 3.5 é«˜çº§èƒ½åŠ›â€”â€”æµç¨‹â€œä¸­æ–­â€ä¸â€œå­˜æ¡£â€
ç°å®ç ´æ¡ˆä¸­ï¼Œç»„é•¿å¯èƒ½éœ€è¦ä¸­é€”å–Šåœï¼Œè®©å¤§å®¶é‡æ–°å®¡è§†è¯æ®ã€‚LangGraph é€šè¿‡ **`Checkpointer`** å’Œ **`Interrupts`** æ”¯æŒè¿™ä¸€åœºæ™¯ã€‚

```python
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver

# å¼•å…¥ä¸€ä¸ª"æ¡£æ¡ˆç®¡ç†å‘˜"ï¼ˆè®°å¿†å­˜å‚¨å™¨ï¼‰ï¼Œè´Ÿè´£ä¿å­˜æ¯ä¸€è½®çš„å¿«ç…§
memory = MemorySaver()

# é‡æ–°ç¼–è¯‘å·¥ä½œæµï¼Œå¹¶æŒ‡å®šåœ¨ â€˜analystâ€™ èŠ‚ç‚¹æ‰§è¡Œå‰å¿…é¡»ä¸­æ–­ï¼Œç­‰å¾…æŒ‡ä»¤
workflow_builder = StateGraph(CaseFileState)
workflow_builder.add_node("detective", detective_node)
workflow_builder.add_node("analyst", analyst_node)
workflow_builder.add_edge(START, "detective")
workflow_builder.add_edge("detective", "analyst")
workflow_builder.add_edge("analyst", END)

# å…³é”®ï¼šé…ç½® checkpoint å’Œ interrupt
investigation_workflow = workflow_builder.compile(
    checkpointer=memory, interrupt_before=["analyst"]  # æŒ‡å®šåœ¨ â€˜analystâ€™ èŠ‚ç‚¹å‰ä¸­æ–­
)

# æ‰§è¡Œæ—¶ï¼Œéœ€è¦æä¾›ä¸€ä¸ª thread_idï¼Œç±»ä¼¼äº"æ¡ˆä»¶ç¼–å·"
config = {"configurable": {"thread_id": "case-001"}}
initial_state = {"clues": [], "investigation_log": []}

# ç¬¬ä¸€è½®æ‰§è¡Œï¼Œä¼šåœ¨ analyst æ‰§è¡Œå‰è‡ªåŠ¨æš‚åœ
result = investigation_workflow.invoke(initial_state, config=config)
print("æµç¨‹å·²æš‚åœåœ¨ analyst èŠ‚ç‚¹å‰ã€‚")
print("å½“å‰çŠ¶æ€ï¼š", investigation_workflow.get_state(config).values)

# æ¨¡æ‹Ÿç»„é•¿å®¡é˜…åï¼Œå†³å®šç»§ç»­
user_input = input("\næ˜¯å¦æ‰¹å‡†æƒ…æŠ¥å‘˜å¼€å§‹åˆ†æï¼Ÿ (yes/no): ")
if user_input.lower() == "yes":
    # ä¼ å…¥ None è¡¨ç¤ºä»å½“å‰ä¸­æ–­å¤„ç»§ç»­æ‰§è¡Œ
    final_state = investigation_workflow.invoke(None, config=config)
    print("\nè°ƒæŸ¥å®Œæˆã€‚æœ€ç»ˆçŠ¶æ€ï¼š", final_state)
else:
    print("\nè°ƒæŸ¥æš‚åœã€‚")
```

æ­¤å¤–ï¼Œä½ è¿˜å¯ä»¥éšæ—¶æŸ¥çœ‹è¿™ä¸ªæ¡ˆä»¶ï¼ˆ`thread_id`ï¼‰çš„æ‰€æœ‰å†å²è®°å½•ï¼š
```python
for snapshot in investigation_workflow.get_state_history(config):
    print(â€œ-â€ * 20)
    print(â€œæ­¥éª¤å¿«ç…§ï¼šâ€, snapshot.values)
    print(â€œä¸‹ä¸€æ­¥æ‰§è¡Œï¼šâ€, snapshot.next)
```

> ğŸ’¡ å¯ä»¥æŠŠå®ƒæƒ³è±¡thread_idæˆä¼šè¯ IDï¼Œä½†èŒƒå›´æ›´å¹¿ï¼šå®ƒä¸ä»…é™äºç”¨æˆ·èŠå¤©ã€‚å®ƒå®šä¹‰äº† LangGraph ä¸­ä¸€ä¸ªå®Œæ•´çš„é€»è¾‘æµç¨‹ã€‚å¦‚æœæ›´æ”¹æ­¤ ID thread_idï¼ŒLangGraph ä¼šå¯åŠ¨ä¸€ä¸ªå…¨æ–°çš„çº¿ç¨‹â€”â€”ä¸ä¼šè®°ä½ä¹‹å‰çš„çº¿ç¨‹ã€‚

thread_id å¯ä»¥å®ç°ï¼š
1. æ§åˆ¶å†…å­˜èŒƒå›´
2. æ¢å¤å·²ä¸­æ–­æµç¨‹çš„æ‰§è¡Œ
3. å¯ä»¥è®¾è®¡äº’ä¸å†²çªçš„å¹¶è¡Œä»»åŠ¡

å¸¸è§çš„ thread_id çš„ç­–ç•¥ï¼š
- Chat session: user-{id}-chat-{timestamp}
- Document task: file-{file_id}-run_{uuid}
- Learning agent: user-{id}-topic-{topic_id}
- Multi-agent: task-{tieket_id}

å¯¹äºç”Ÿäº§ç¯å¢ƒï¼Œä½¿ç”¨ç”±æ•°æ®åº“ä½œä¸ºcheckpointsçš„å­˜å‚¨
```bash
pip install langgraph-checkpoint-postgres
```

ç¤ºä¾‹ä»£ç ï¼š
```python
from langchain.agents import create_agent

from langgraph.checkpoint.postgres import PostgresSaver  


DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable"
with PostgresSaver.from_conn_string(DB_URI) as checkpointer:
    checkpointer.setup() # auto create tables in PostgresSql
    agent = create_agent(
        "gpt-5",
        tools=[get_user_info],
        checkpointer=checkpointer,  
    )
```

## 4. è¿›é˜¶ï¼šæ„å»ºå¯å¾ªç¯çš„å·¥ä½œæµ
LangGraph ä¸ä»…æ”¯æŒçº¿æ€§æµç¨‹ï¼Œè¿˜èƒ½è½»æ¾å®ç°å¸¦å¾ªç¯çš„å¤æ‚å·¥ä½œæµã€‚

```python {61-63}
from typing import TypedDict, Literal
from typing_extensions import Annotated
from langgraph.graph import StateGraph, START, END
from datetime import datetime


class Task(TypedDict):
    id: str
    description: str
    status: Literal["pending", "in_progress", "completed"]
    created_at: str
    updated_at: str | None


class TaskManagerState(TypedDict):
    #  ä½¿ç”¨è‡ªå®šä¹‰ reducerï¼šæ–°ä»»åŠ¡åˆ—è¡¨ç›´æ¥æ›¿æ¢æ—§åˆ—è¡¨
    tasks: Annotated[list[Task], lambda old, new: new]


def add_init_tasks(state):
    return {
        "tasks": [
            {
                "id": f"task_{i}",
                "description": f"Sample task {i}",
                "status": "pending",
                "created_at": datetime.now().isoformat(),
                "updated_at": None,
            }
            for i in range(1, 4)
        ]
    }


def process_next_task(state):
    tasks = state["tasks"]
    now = datetime.now().isoformat()
    for i, task in enumerate(tasks):
        if task["status"] == "pending":
            updated_task = {**task, "status": "completed", "updated_at": now}
            # æ„é€ æ–°ä»»åŠ¡åˆ—è¡¨ï¼ˆæ›¿æ¢è¯¥ä»»åŠ¡ï¼‰
            new_tasks = tasks[:i] + [updated_task] + tasks[i + 1 :]
            return {"tasks": new_tasks}
    return {}  # æ— å¾…åŠä»»åŠ¡ï¼Œä¸æ›´æ–°çŠ¶æ€


def should_continue(state):
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­å¾ªç¯"""
    has_pending = any(t["status"] == "pending" for t in state["tasks"])
    return "process" if has_pending else END


# æ„å»ºçŠ¶æ€å›¾
builder = StateGraph(TaskManagerState)
builder.add_node("add", add_init_tasks)
builder.add_node("process", process_next_task)

builder.add_edge(START, "add")
builder.add_edge("add", "process")

builder.add_conditional_edges(
    "process", should_continue, ["process", END]  # å¯èƒ½çš„ä¸‹ä¸€èŠ‚ç‚¹ï¼šç»§ç»­å¤„ç†æˆ–ç»“æŸ
)
graph = builder.compile()

result = graph.invoke({"tasks": []})

for task in result["tasks"]:
    print(f"âœ… {task['id']}: {task['description']} â†’ {task['status']}")
```


## 5. create_agent
LangChain ç»™å‡ºçš„å®˜æ–¹ç¤ºä¾‹ï¼Œæä¾›äº†ä¸€ä¸ªåˆ›å»ºæ™ºèƒ½ä»£ç†çš„å‡½æ•°ï¼š`create_agent`

```python
from httpx import request
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI  # ä½¿ç”¨ OpenAI å…¼å®¹å®¢æˆ·ç«¯
import requests
from langgraph.checkpoint.memory import MemorySaver


def get_weather(city: str) -> str:
    """Get weather for a given city."""
    response = requests.get(f"https://wttr.in/{city}?format=j1")
    return response.json()


# é…ç½®ç¡…åŸºæµåŠ¨çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ DeepSeekã€Qwenã€Llama ç­‰ï¼‰
llm = ChatOpenAI(
    model="Qwen/Qwen3-8B",  # æˆ–å…¶ä»– SiliconFlow æ”¯æŒçš„æ¨¡å‹
    api_key="api_key",
    base_url="https://api.siliconflow.cn/v1",
    temperature=0.0,
)
memory = MemorySaver()  # [!code highlight]

checkpointer = memory
config = {"configurable": {"thread_id": "test-thread"}}

agent = create_agent(
    model=llm,
    tools=[get_weather],
    system_prompt="You are a helpful assistant",
    checkpointer=memory,
)

# Run the agent
result = agent.invoke(
    {"messages": [{"role": "user", "content": "what is the weather in Beijing"}]},
    config=config,
)
for snapshot in agent.get_state_history(config):
    print(snapshot)

```
::: warning
æ‰§è¡Œä»£ç éœ€è¦å®‰è£… langchain-openai ä¾èµ–ï¼Œ`pip install langchain-openai`
:::

> ğŸ“¦ æœ¬è´¨ï¼š`create_agent` æ˜¯ LangGraph çš„é«˜çº§å°è£…â€”â€”å®ƒè‡ªåŠ¨æ„å»ºäº†ä¸€ä¸ªåŒ…å« â€œLLM â†’ Tool â†’ LLMâ€ å¾ªç¯çš„çŠ¶æ€å›¾ï¼Œå¹¶å†…ç½®äº†æ¶ˆæ¯ç®¡ç†ã€å·¥å…·è·¯ç”±å’Œ checkpoint æ”¯æŒã€‚

æˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡ä½¿ç”¨ `ToolStrategy` æ¥å®šä¹‰è¾“å‡ºçš„ç»“æ„ï¼Œå…¶å®å°±æ˜¯åœ¨è°ƒç”¨LLMçš„æ—¶å€™ï¼ŒåŠ å…¥äº†æ ¼å¼çš„æŒ‡å¯¼ï¼ŒåŒæ—¶å¯¹æ¨¡å‹çš„è¾“å‡ºï¼ˆå¯èƒ½æ˜¯æ¯”è¾ƒå¥½å¤„ç†çš„ç»“æ„ï¼Œä¹Ÿå¯ä»¥ä¸æ˜¯å¾ˆå¥½å¤„ç†çš„ç»“æ„ï¼‰è¿›è¡Œè§£æï¼Œè¿”å›ä¸€ä¸ªç»“æ„åŒ–çš„ç»“æœã€‚
```python
from typing import Optional, List
from pydantic import BaseModel, Field
from pydantic import BaseModel
from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy
from langchain_openai import ChatOpenAI


class PartialContact(BaseModel):
    name: Optional[str] = None
    email: Optional[str] = None
    phone: Optional[str] = None
    found_fields: List[str] = Field(default_factory=list)


# å…è®¸éƒ¨åˆ†æå–
llm = ChatOpenAI(
    model="Qwen/Qwen3-8B",  # æˆ–å…¶ä»– SiliconFlow æ”¯æŒçš„æ¨¡å‹
    api_key="your api key",
    base_url="https://api.siliconflow.cn/v1",
    temperature=0.0,
)


agent = create_agent(
    model=llm,
    system_prompt="You are a helpful assistant",
    response_format=ToolStrategy(PartialContact),
)

# è°ƒç”¨ä»£ç†
result = agent.invoke(
    {
        "messages": [
            {
                "role": "user",
                "content": "æå–è”ç³»ä¿¡æ¯ï¼šå¼ ä¸‰ï¼Œzhangsan@example.comï¼Œ13800138000",
            }
        ]
    }
)

# è·å–ç»“æ„åŒ–å“åº”
contact = result["structured_response"]
print(contact)
# ContactInfo(name='å¼ ä¸‰', email='zhangsan@example.com', phone='13800138000')

print(result["messages"][-1])
```

> ğŸ’¡ è¿™é‡Œå°±éœ€è¦æ³¨æ„ï¼Œå› ä¸ºLLMçš„è¾“å‡ºä¸ç¡®å®šï¼Œæ‰€ä»¥æœ€ç»ˆçš„ç»“æ„åŒ–ç»“æœå¦‚æœä¸ç¬¦åˆé¢„æœŸï¼Œéƒ¨åˆ†åŸå› å¯èƒ½åœ¨LLMçš„è¾“å‡ºï¼Œå¦ä¸€éƒ¨åˆ†åŸå› å¯èƒ½åœ¨ `ToolStrategy` å¯¹ç»“æœçš„è§£æï¼Œ`ToolStrategy`çš„ç»“æœè¢«ä¿å­˜åœ¨äº† `structured_response` çš„ key ä¸­ã€‚

é™¤äº† `ToolStrategy` ä¹‹å¤–ï¼Œè¿˜æœ‰ `AutoToolStrategy` ä»¥åŠ `ProviderStrategy`ã€‚

- ProviderStrategy æ˜¯é’ˆå¯¹ä¸åŒæ¨¡å‹æä¾›å•†ï¼ˆå¦‚ OpenAIã€Anthropicã€Google ç­‰ï¼‰çš„ç‰¹æ€§è¿›è¡Œä¼˜åŒ–çš„ç­–ç•¥ã€‚ä¸åŒçš„æ¨¡å‹æä¾›å•†å¯èƒ½æœ‰ä¸åŒçš„ç»“æ„åŒ–è¾“å‡ºæ–¹å¼ï¼ŒProviderStrategy ä¼šåˆ©ç”¨å„æä¾›å•†çš„åŸç”Ÿç‰¹æ€§ã€‚

- AutoToolStrategy æ˜¯ä¸€ä¸ªè‡ªåŠ¨é€‰æ‹© ToolStrategy çš„ç­–ç•¥ã€‚å®ƒä¼šè‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„ ToolStrategyï¼Œå¹¶ä½¿ç”¨å®ƒæ¥å¤„ç†é—®é¢˜ã€‚

## 6. å¤šè½®é—®ç­”æœºå™¨äºº
ä»ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œmodel èŠ‚ç‚¹å®é™…ä¸Šæ˜¯ä¸€ä¸ªæ¯”è¾ƒç‰¹æ®Šçš„Nodeè€Œå·²ï¼ˆåœ¨LangChainçš„è®¾è®¡ä¸­ï¼Œè¿™äº›å¯ä»¥è¿è¡Œçš„Nodeéƒ½å±äº Runnable ï¼‰ï¼Œå®ƒæ¥å—ä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨ï¼ˆ`List[BaseMessage]`ï¼‰ï¼Œè¾“å‡ºä¸€ä¸ª `AIMessage`ã€‚è€Œç”¨æˆ·è¾“å…¥ä¹Ÿå¯ä»¥è¢«å°è£…ä¸º `HumanMessage` â€”â€” è¿™æ„å‘³ç€ï¼Œâ€œç”¨æˆ·â€å®Œå…¨å¯ä»¥è¢«è§†ä¸ºä¸€ä¸ªç‰¹æ®Šçš„â€œå·¥å…·â€æˆ–â€œå¤–éƒ¨èŠ‚ç‚¹â€ï¼Œä¸ LLM åœ¨çŠ¶æ€å›¾ä¸­äº¤æ›¿äº¤äº’ã€‚

ä¸‹é¢çš„ä¾‹å­å®Œå…¨å»æ‰äº†builderï¼Œç›´æ¥ä½¿ç”¨ while å¾ªç¯å®ç°å¤šè½®é—®ç­”ï¼š
```python
from httpx import request
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI  # ä½¿ç”¨ OpenAI å…¼å®¹å®¢æˆ·ç«¯
from langchain.messages import SystemMessage, AIMessage, HumanMessage

# é…ç½®ç¡…åŸºæµåŠ¨çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ DeepSeekã€Qwenã€Llama ç­‰ï¼‰
model = ChatOpenAI(
    model="Qwen/Qwen3-8B",  # æˆ–å…¶ä»– SiliconFlow æ”¯æŒçš„æ¨¡å‹
    api_key="your api key",
    base_url="https://api.siliconflow.cn/v1",
    temperature=0.0,
)

system_message = SystemMessage(
    content="ä½ å«å°èŠ±ï¼Œæ˜¯ä¸€åä¹äºåŠ©äººçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·åœ¨å¯¹è¯ä¸­ä¿æŒå‹å¥½çš„æ€åº¦ã€‚"
)

messages = [system_message]

while True:
    user_input = input("ç”¨æˆ·ï¼š")
    if user_input.lower() in {"exit", "quit"}:
        print("ç»“æŸå¯¹è¯")
        break

    # è¿½åŠ ç”¨æˆ·æ¶ˆæ¯
    messages.append(HumanMessage(content=user_input))

    # è·å–æ¨¡å‹ç”Ÿæˆçš„å›å¤
    print("æ¨¡å‹ï¼š", end="", flush=True)
    full_reply = ""

    for chunk in model.stream(messages):
        if chunk.content:
            print(chunk.content, end="", flush=True)
            full_reply += chunk.content

    print("\n" + "-" * 40)

    messages.append(AIMessage(content=full_reply))

    # ä»…ä¿ç•™æœ€æ–°50æ¡æ¶ˆæ¯
    messages = messages[-50:]
```

> ğŸ’¡ æ‰§è¡Œå‰è®°å¾—æ›´æ–° api key

## 7. ä¸­é—´ä»¶
å®˜æ–¹å‚è€ƒæ–‡æ¡£ï¼š[å†…ç½®çš„ä¸­é—´ä»¶é“¾æ¥](https://docs.langchain.com/oss/python/langchain/middleware/built-in)

<Image 
src='./assets/langchain_middleware.png'
width='50%'
/>

### 7.1 åŠ¨æ€æ¨¡å‹
åœ¨å­¦ä¹ åˆ°è¿™é‡Œçš„æ—¶å€™ï¼Œæˆ‘ä»¬åº”è¯¥å¯¹ LangChain çš„åŸºæœ¬æ¦‚å¿µæœ‰äº†ä¸€å®šçš„äº†è§£ï¼Œå…¶æ•´ä½“çš„é“¾è·¯åº”è¯¥æ˜¯ReActæ¨¡å¼ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

<Image
  src="./assets/langchain_v1_1.png"
  alt="langchain ReActæ¨¡å¼"
  width="50%"
  align="center"
  :card="false"
/>

è¿™é‡Œçš„modelæ˜¯é™æ€ç»™å®šçš„ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æ ¹æ®å®é™…çš„ä¸šåŠ¡åœ¨è¿è¡Œè¿‡ç¨‹ä¸­åŠ¨æ€é€‰æ‹©æ¨¡å‹ï¼Œæ¯”å¦‚æ ¹æ®ç”¨æˆ·çš„è¾“å…¥åŠ¨æ€é€‰æ‹©æ¨¡å‹ï¼Œæˆ–è€…æ ¹æ®ç”¨æˆ·çš„è¾“å…¥åŠ¨æ€é€‰æ‹©æ¨¡å‹å‚æ•°ï¼Œæˆ–è€…æ ¹æ®ç”¨æˆ·çš„è¾“å…¥åŠ¨æ€é€‰æ‹©æ¨¡å‹è¾“å…¥å‚æ•°ç­‰ç­‰ã€‚

```python
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse

basic_model = ChatOpenAI(model="gpt-3.5-turbo")
advanced_model = ChatOpenAI(model="gpt-4")

@wrap_model_call
def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:
    message_count = len(request.state["messages"])

    if message_count > 10:
        # Use an advanced model for longer conversations
        model = advanced_model
    else:
        model = basic_model

    return handler(request.override(model=model))

agent = create_agent(
    model=basic_model,  # Default model
    tools=tools,
    middleware=[dynamic_model_selection]
)
```

### 7.2 è‡ªå®šä¹‰å·¥å…·é”™è¯¯å¤„ç†æ–¹å¼
å¯ä»¥ä½¿ç”¨ `wrap_tool_call` è£…é¥°å™¨æ¥å¤„ç†å·¥å…·è°ƒç”¨çš„é”™è¯¯ï¼Œå®é™…ä¸Šå°±æ˜¯æŠŠå·¥å…·çš„é”™è¯¯å¤„ç†é€»è¾‘å°è£…æˆä¸­é—´ä»¶ï¼Œç„¶åæ·»åŠ åˆ° `middleware` åˆ—è¡¨ä¸­ã€‚
```python
def wrap_tool_call(
    func: _CallableReturningToolResponse | None = None,
    *,
    tools: list[BaseTool] | None = None,
    name: str | None = None,
) -> (
    Callable[
        [_CallableReturningToolResponse],
        AgentMiddleware,
    ]
    | AgentMiddleware
)
```
è¿™ä¸ªä¸­é—´ä»¶çš„wrap_tool_callå‡½æ•°ï¼Œä¼šè¢«æ·»åŠ åˆ° ToolNode çš„å®ä¾‹åŒ–çš„è¿‡ç¨‹ä¸­ï¼Œå› æ­¤å¯¹æ‰€æœ‰ Client-side çš„Toolï¼Œéƒ½ä¼šæ·»åŠ è¿™ä¸ªä¸­é—´ä»¶ã€‚

> ğŸ’¡ Client-side æ„å‘³ç€æ˜¯åœ¨ç”¨æˆ·çš„æœ¬åœ°ç¯å¢ƒè¦æ‰§è¡Œï¼Œå¯¹äºLLMï¼Œåˆ™æ˜¯Server sideï¼Œé€šè¿‡APIè®¿é—®çš„æ–¹å¼è·å–ç»“æœï¼Œå¹¶ä¸æ˜¯åœ¨ç”¨æˆ·æœ¬åœ°ç¯å¢ƒæ‰§è¡Œæ¨ç†ã€‚

```python
from langchain.agents import create_agent
from langchain.agents.middleware import wrap_tool_call
from langchain.messages import ToolMessage


@wrap_tool_call
def handle_tool_errors(request, handler):
    """Handle tool execution errors with custom messages."""
    try:
        return handler(request)
    except Exception as e:
        # Return a custom error message to the model
        return ToolMessage(
            content=f"Tool error: Please check your input and try again. ({str(e)})",
            tool_call_id=request.tool_call["id"]
        )

agent = create_agent(
    model="gpt-4o",
    tools=[search, get_weather],
    middleware=[handle_tool_errors]
)
```

### 7.3 è‡ªå®šä¹‰ StateSchema
LangChain 1.0 åšäº†å¤§é‡çš„å°è£…ï¼Œè™½ç„¶è¿˜ä¿ç•™äº† state_schema è¿™ä¸ªé€‰é¡¹ï¼ˆä¸»è¦æ˜¯ä¸ºäº†åšå…¼å®¹ï¼‰ï¼Œä½†å®˜æ–¹æ¨èä½¿ç”¨ä¸­é—´ä»¶è¿›è¡Œå®šä¹‰ã€‚

LangChain ä¸­å·²ç»å®šä¹‰äº†ä¸€ä¸ªç»™ Agent çš„Stateï¼Œæˆ‘ä»¬ä»…éœ€è¦åœ¨å…¶ä¸Šé¢æ·»åŠ è‡ªå·±çš„ schema å³å¯ã€‚

```python
# langchain v1.0
class AgentState(TypedDict, Generic[ResponseT]):
    """State schema for the agent."""

    messages: Required[Annotated[list[AnyMessage], add_messages]]
    jump_to: NotRequired[Annotated[JumpTo | None, EphemeralValue, PrivateStateAttr]]
    structured_response: NotRequired[Annotated[ResponseT, OmitFromInput]]
```

### 7.3 ä¿®å‰ªæ¶ˆæ¯
å¤§å¤šæ•° LLM éƒ½æœ‰æœ€å¤§æ”¯æŒçš„ä¸Šä¸‹æ–‡çª—å£ï¼ˆä»¥æ ‡è®°ä¸ºå•ä½ï¼‰ã€‚å¯ä»¥åœ¨ before_model çš„æ—¶å€™ï¼Œå¯¹æ¶ˆæ¯è¿›è¡Œä¿®å‰ªã€‚

```python
@before_model
def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    """Keep only the last few messages to fit context window."""
    messages = state["messages"]

    if len(messages) <= 3:
        return None  # No changes needed

    first_msg = messages[0]
    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]
    new_messages = [first_msg] + recent_messages

    return {
        "messages": [
            RemoveMessage(id=REMOVE_ALL_MESSAGES),
            *new_messages
        ]
    }
# create_agent ä¸­æŠŠ trim_messages æ·»åŠ åˆ° middleware ä¸­
```

å¯ä»¥åœ¨æ°å½“çš„æ—¶æœºè¿›è¡ŒæŒ‡å®šå†å²æ¶ˆæ¯çš„åˆ é™¤ï¼Œä½¿ç”¨ langchain çš„ RemoveMessage æ–¹æ³•

```python
from langchain.messages import RemoveMessage

@after_model
def delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:
    """Remove old messages to keep conversation manageable."""
    messages = state["messages"]
    if len(messages) > 2:
        # remove the earliest two messages
        return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}
    return None
```
### 7.4 SummarizationMiddleware
å¦‚æœå•çº¯åœ°åˆ é™¤æ¶ˆæ¯ï¼Œå¯èƒ½ä¼šå› ä¸ºæ¶ˆæ¯é˜Ÿåˆ—çš„æ¸…ç†è€Œä¸¢å¤±ä¿¡æ¯ã€‚ç›¸æ¯”ä¹‹å‰ï¼Œæ›´åˆé€‚çš„æ–¹æ³•æ˜¯å¯¹ä¹‹å‰çš„æ¶ˆæ¯è¿›è¡Œæ±‡æ€»ã€æç‚¼ã€‚ä¸è¿‡æ—¢ç„¶è¦æ±‡æ€»ï¼Œé‚£ä¹ˆå°±éœ€è¦å€Ÿç”¨LLMæ¨¡å‹äº†ï¼Œå› æ­¤éœ€è¦é¢å¤–é…ç½®å¯¹åº”çš„modelã€‚
```python
from langchain.agents import create_agent
from langchain.agents.middleware import SummarizationMiddleware
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.runnables import RunnableConfig


checkpointer = InMemorySaver()

agent = create_agent(
    model="gpt-4o",
    tools=[],
    middleware=[
        SummarizationMiddleware(
            model="gpt-4o-mini",
            trigger=("tokens", 4000),
            keep=("messages", 20)
        )
    ],
    checkpointer=checkpointer,
)

config: RunnableConfig = {"configurable": {"thread_id": "1"}}
agent.invoke({"messages": "hi, my name is bob"}, config)
agent.invoke({"messages": "write a short poem about cats"}, config)
agent.invoke({"messages": "now do the same but for dogs"}, config)
final_response = agent.invoke({"messages": "what's my name?"}, config)

final_response["messages"][-1].pretty_print()
```

### 7.5 è‡ªå®šä¹‰ä¸­é—´ä»¶
```python
from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse
from typing import Callable


@wrap_model_call
def retry_model(
    request: ModelRequest,
    handler: Callable[[ModelRequest], ModelResponse],
) -> ModelResponse:
    for attempt in range(3):
        try:
            return handler(request)
        except Exception as e:
            if attempt == 2:
                raise
            print(f"Retry {attempt + 1}/3 after error: {e}")
```

Nodeé£æ ¼ï¼š
- `@before_agent` - åœ¨ä»£ç†å¯åŠ¨å‰è¿è¡Œï¼ˆæ¯æ¬¡è°ƒç”¨è¿è¡Œä¸€æ¬¡ï¼‰
- `@before_model` - åœ¨æ¯æ¬¡æ¨¡å‹è°ƒç”¨ä¹‹å‰è¿è¡Œ
- `@after_model` - åœ¨æ¯æ¬¡æ¨¡å‹å“åº”åè¿è¡Œ
- `@after_agent` - åœ¨ä»£ç†ç¨‹åºå®Œæˆåè¿è¡Œï¼ˆæ¯æ¬¡è°ƒç”¨ä¸€æ¬¡ï¼‰
wrapé£æ ¼ï¼š
- `@wrap_model_call` - ä½¿ç”¨è‡ªå®šä¹‰é€»è¾‘åŒ…è£…æ¯ä¸ªæ¨¡å‹è°ƒç”¨
- `@wrap_tool_call` - ä½¿ç”¨è‡ªå®šä¹‰é€»è¾‘åŒ…è£…æ¯ä¸ªå·¥å…·è°ƒç”¨
å…¶ä»–ï¼š
- `@dynamic_prompt` - ç”ŸæˆåŠ¨æ€ç³»ç»Ÿæç¤º


## 8. Tool Runtime
å·¥å…·å¯ä»¥é€šè¿‡ToolRuntimeè®¿é—®è¿è¡Œæ—¶ï¼Œè¯¥å‚æ•°æä¾›ï¼š

- çŠ¶æ€- åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­æµåŠ¨çš„å¯å˜æ•°æ®ï¼ˆä¾‹å¦‚ï¼Œæ¶ˆæ¯ã€è®¡æ•°å™¨ã€è‡ªå®šä¹‰å­—æ®µï¼‰
- ä¸Šä¸‹æ–‡- ä¸å¯å˜é…ç½®ï¼Œä¾‹å¦‚ç”¨æˆ· IDã€ä¼šè¯è¯¦ç»†ä¿¡æ¯æˆ–åº”ç”¨ç¨‹åºç‰¹å®šé…ç½®
- å­˜å‚¨- è·¨å¯¹è¯çš„æŒä¹…é•¿æœŸè®°å¿†
- æµå†™å…¥å™¨- å·¥å…·æ‰§è¡Œæ—¶æµå¼è‡ªå®šä¹‰æ›´æ–°
- é…ç½®-RunnableConfigç”¨äºæ‰§è¡Œ
- å·¥å…·è°ƒç”¨ ID - å½“å‰å·¥å…·è°ƒç”¨çš„ ID


<Image 
  src='./assets/tool_runtime.svg'
  width='100%'
/>

å¦‚æœè¦è°ƒç”¨ä¹‹å‰æˆ‘ä»¬åˆ›å»ºçš„ custom stateï¼Œå¯ä»¥é€šè¿‡ runtime è¿›è¡Œè®¿é—®
```python
# Access custom state fields
@tool
def get_user_preference(
    pref_name: str,
    runtime: ToolRuntime  # ToolRuntime parameter is not visible to the model
) -> str:
    """Get a user preference value."""
    preferences = runtime.state.get("user_preferences", {})
    return preferences.get(pref_name, "Not set")
```

## æ€»ç»“
langchain æ˜¯é€šè¿‡å¤§é‡çš„å°è£…ï¼Œæ„å»ºä¸€ä¸ªçœ‹ç€æ¯”è¾ƒç®€å•çš„graphï¼ŒåŸºäºGoogleçš„Pregel æ¨¡å‹è¿›è¡Œå®ç°ï¼Œå®ç°çš„é‡ç‚¹æ˜¯åœ¨äºä¸å…¶ä»–å‡½æ•°çš„é›†æˆã€‚

## ä¸‹ä¸€æ­¥
å†™ä¸€ä¸ªåŸºäº LangChain å®ç°çš„ RAG piplinesã€‚


